---
layout: static1
title: Saving Time With User-Centered Design
permalink: /cw-assessment
---
<h1>The Challenge</h1>
Each year, the Cadet Wing (CW) assesses the over 4000 cadets at the US Air Force Academy. 
Two components of this&mdash;the personal appearance inspection and cadet interview&mdash;had been carried out on paper or used a survey tool to log responses. 
This process required hundreds of hours of work to compile and analyze the data at the end of the assessment period, aside from the number of hours spent carrying out the inspections and interviews. 
With the recent acquisition of a Learning Management System (LMS), the CW wanted to utilize the LMS to save time and have all the data entered and stored in one location. 
They contacted our team, and I took the lead on this project, carrying out the design and development of the products, and providing training on how to use them. 
<br>
<h1>The Iterative Design Process</h1>
<p>At our kickoff meeting, the CW leadership stated their goals for this project and described how the inspection and interview took place.
  Given the nature of the project, I determined that iterative design was the best way to arrive the optimal products. 
  So, we agreed to meet at regular intervals so I could show them working prototypes and conduct usability testing.</p>

<p>Given my knowledge of the LMS, I developed initial prototypes using two different tools in the LMS. 
  During my second meeting, my goal was to come to a decision on which tool to use for each component of the assessment.
  To accomplish this, I asked questions to obtain their preferences on: 
<ul>
  <li> How data was put into the system; </li>
  <li> How and what data would be pulled out of the system; </li>
  <li> What sorts of workflows were ideal, acceptable, and unacceptable.</li>
</ul>
Their responses led us to conclude that the rubric tool was the best one to use for both the inspection (a straightforward use of a rubric) and the interview (a rather innovative use of the tool).
This decision hinged on four considerations:
<ol>
  <li> Assessors would only need to learn and use on tool instead of two.</li>
  <li> The workflow for the assessor was simplified: given their preferences for data entry, the workflow for the other tool I suggested as a possible solution would require using multiple accounts and thereby slow down the assessment process.</li>
  <li> Given their preferences for pulling data, the data retrieval with a rubric would be much cleaner than the other tool.</li>
  <li> The ability to provide written feedback in addition to a numerical score.</li>
  <li> The ability to track which interview questions were asked (since the interviewer was allowed to ask one of several questions per category).</li>
</ol>
</p>
<p> Our subsequent meetings were spent working out three components of the user experience: how the assessor would select the appropriate rubric; how each rubric would calculate points; and whether to include an automatically assigned pass/fail grade after the assessment and, if so, whether to color code it.</p>
 
<h2>Choosing the Right Rubric</h2>
<p>For getting the right rubric, we had to decide:
  <ul>
    <li> The best way to group the cadets (create one course in the LMS with all of the cadets, create one course per class year, create one class per squadron, etc).</li>
    <li> The best way to access the rubrics within a course.</li>
</ul>
Ultimately, it made the most sense to have one course per class year.</p>

<p>Within the LMS, a rubric is associated with a column in the course’s gradebook. 
  Any column can have more than one rubric associated with it. 
  With the personal appearance inspection, there were two different rubrics, depending on the choice of uniform. 
  So, one way to place the rubrics in the course was to associate both with one column, which would look like this:<br>
  <img src="/img/01-RubricSelection.PNG" alt="Choosing between the two rubrics" style="height:150px"></p>

<p> Once they made their choice, they would see the rubric they selected, as well as a choice to use the other rubric (see top-right):<br>
  <img src="/img/02-Rubric1.PNG" alt="The first rubric option" style="height:350px"><br>
After filling out the selected rubric they could submit the score or move onto the next one and submit:<br>
  <img src="/img/02-Rubric2.PNG" alt="The second rubric option" style="height:350px"><br>
One downside of this approach is that it would be easy to mistakenly fill in the wrong rubric: seeing <q>1 of 2</q> might make an assessor believe they had two rubrics to fill in instead of one.</p>


  <h2>Assign Points</h2>

  <h2>Assigning a Grade</h2>

<h1>Outcome</h1>
<p>Once the design process was over, I trained over 80 people who would either use the rubrics or train others on how to use the rubrics. 
  The feedback we received at the end of the assessment period was overwhelmingly positive. 
  Among the positive feedback we received was a letter of commendation from the Vice Commandant of Cadets noting how <q>Dr. Padgett’s innovative placement of the Personal Appearance Inspection (PAI) into Blackboard is a game changer for us</q>. 
  And the numbers do not lie about that: not only were the users happy with the experience provided by the rubrics, but overall these rubrics saved CW staff 915 hours of work (per assessment cycle)!</p>
